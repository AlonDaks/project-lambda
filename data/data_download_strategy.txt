Our project dataset requires downloading 20 .TGZ files, one per subject. Each
.TGZ is 16 GBs. This file outlines how we plan on downloaded the data since that
itself is not trivial.

Each team member is tasked to download data for five subjects. Each subject
takes about 1.5 hours to download. Team members will place their downloaded
.TGZs on an external hard-drive. Then, team members will meet in person to
transfer .TGZs among each other. Each transfer takes less than 10 minutes, which
reduces the total download time from ~30 hours to ~10 hours.

Once we everyone has all the data, we will unpack the .TGZs and see precisely
which files we are going to use for our analysis. Keeping only the files we
intend to use, we will upload the data to Google Drive. We will then write
appropriate download scripts interfacing with the Google Drive data repository.

Below outlines which team member is responsible for downloading each subject's
.TGZ:

Alon: Subjects 1-5
Lisa: Subjects 6-10
Ying: Subjects 11-15
Jordeen: Subjects 16-20

The project includes a README on the dataset that details what each .TGZ
contains, and from that we can decide what information we can extract and use.
We are going to be focusing on fMRI data, and so we decided to exclude
everything else. Both the raw data as well as the adjusted versions are given,
but we are only going to use the corrected version. And we will be using the
data with linear anatomical alignment which is said to be suitable for group
analyses and inter-individual comparisons. Thus the resulting files
are

./sub001/BOLD/task001_run001/bold_dico_dico7Tad2grpbold7Tad.nii.gz
  BOLD data

./sub001/BOLD/task001_run001/bold_dico_brainmask_dico7Tad2grpbold7Tad.nii.gz
  Matching brain mask volume

./sub001/BOLD/task001_run001/bold_dico_xfm_dico7Tad2grpbold7Tad.mat
  4x4 affine transformation matrix (plain text format)

Upon expanding the .gz files, there is approximately 8 GBs worth of data
for each subject, thus reducing the size by half. It's still quite a lot.

